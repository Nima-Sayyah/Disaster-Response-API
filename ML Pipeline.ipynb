{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdaa26a9",
   "metadata": {},
   "source": [
    "# ML Pipeline\n",
    "Applied commands that constitude an Machine Learning (ML) Pipeline.\n",
    "### Libraries & Datasets\n",
    "- Import Python libraries\n",
    "- Load dataset from database \n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "023b376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/NS/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/NS/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/NS/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd \n",
    "from sqlalchemy import create_engine\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split,  GridSearchCV \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "nltk.download(['wordnet', 'punkt', 'stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28082bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "\n",
    "engine = create_engine('sqlite:///Data/disaster_messages_database.db')\n",
    "df = pd.read_sql_table('disaster_messages_table',engine)\n",
    "\n",
    "X = df['message']  # Extracting the 'message'column\n",
    "Y = df.iloc[:, 4:] # Extracting classified labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06961e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        0      0            0             0                 0  ...   \n",
       "1        0      0            1             0                 0  ...   \n",
       "2        0      0            0             0                 0  ...   \n",
       "3        1      0            1             0                 1  ...   \n",
       "4        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6832f46",
   "metadata": {},
   "source": [
    "### Tokenization Function For Text Data Processing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6286cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Function: splits the texts into words and returns the root form of the words\n",
    "    Args:\n",
    "      text(str): the message\n",
    "    Return:\n",
    "      lemm(list of str): a list of the root form of the message words\n",
    "    \"\"\"\n",
    "    # Normalizing text (a-zA-Z0-9 matches all allalphanumeric characters)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # Tokenizing text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Removing stop words\n",
    "    stop = stopwords.words(\"english\")\n",
    "    words = [t for t in words if t not in stop]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemm = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "    return lemm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be920d",
   "metadata": {},
   "source": [
    "### Constructing Machine Learning Pipeline\n",
    "This machine pipeline will take in the `message` column as input and returns classification results on the other 36 categories in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "864c1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipleine 1: Random Forest Classifier\n",
    "\n",
    "pipeline_rfc = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf',  MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Pipeline 2: Naive Bayes classifier\n",
    "\n",
    "pipeline_nbc = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf',  MultiOutputClassifier(MultinomialNB()))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Pipleine 3: Adaboost Classifier \n",
    "\n",
    "pipeline_ada = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf',  MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd3706",
   "metadata": {},
   "source": [
    "### Training Pipelines\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44fbcd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spiliting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ba84113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x7fd0b037eee0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Random Forest Classifier \n",
    "pipeline_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6b31b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x7fd0b037eee0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultiOutputClassifier(estimator=MultinomialNB()))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Naive Bayes classifier \n",
    "pipeline_nbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea129b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x7fd0b037eee0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultiOutputClassifier(estimator=AdaBoostClassifier()))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Adaboost Classifier \n",
    "pipeline_ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf8818",
   "metadata": {},
   "source": [
    "### Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd8c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(y_test, y_pred):\n",
    "    #Testing the model\n",
    "    # Printing the classification report for each label\n",
    "    i = 0\n",
    "    for col in y_test:\n",
    "        print('Feature {}: {}'.format(i+1, col))\n",
    "        print(classification_report(y_test[col], y_pred[:, i]))\n",
    "        i = i + 1\n",
    "    accuracy = (y_pred == y_test.values).mean()\n",
    "    print('The model accuracy is {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f49519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction: the Random Forest Classifier  \n",
    "y_pred = pipeline_rfc.predict(X_test)\n",
    "plot_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe555bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction: the Naive Bayes classifier \n",
    "y_pred = pipeline_nbc.predict(X_test)\n",
    "plot_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a010cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction: the Adaboost Classifier \n",
    "y_pred = pipeline_ada.predict(X_test)\n",
    "plot_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d43887d",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
